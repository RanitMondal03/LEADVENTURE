name: LEADVENTURE TEST

on:
  push:
    branches:
      - master

jobs:
  test:

    runs-on: ubuntu-latest

    steps:

      - name: Checkout repo
        uses: actions/checkout@v4


      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11


      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-html


      - name: Add project to PYTHONPATH
        run: echo "PYTHONPATH=$PYTHONPATH:." >> $GITHUB_ENV

      - name: Set env variables
        run: |
          echo "HUGGINGFACE_API_KEY=${{ secrets.HUGGINGFACE_API_KEY }}" >> $GITHUB_ENV
          echo "AI_BASE_URL=${{ secrets.AI_BASE_URL }}" >> $GITHUB_ENV
          echo "AI_MODEL=${{ secrets.AI_MODEL }}" >> $GITHUB_ENV



      - name: Run tests and create report
        continue-on-error: true
        run: |
          pytest -v --html=report.html --junitxml=report.xml || true

      - name: Surface failing tests
        if: always()
        uses: pmeier/pytest-results-action@main
        with:
          # A list of JUnit XML files, directories containing the former, and wildcard
          # patterns to process.
          # See @actions/glob for supported patterns.
          path: test-results.xml

          # (Optional) Add a summary of the results at the top of the report
          summary: true

          # (Optional) Select which results should be included in the report.
          # Follows the same syntax as `pytest -r`
          display-options: fEX

          # (Optional) Fail the workflow if no JUnit XML was found.
          fail-on-empty: true

          # (Optional) Title of the test results section in the workflow summary
          title: Test results


      - name: Upload test artifacts
        uses: actions/upload-artifact@v4
        with:
          name: test-report
          path: |
            report.xml
            report.html